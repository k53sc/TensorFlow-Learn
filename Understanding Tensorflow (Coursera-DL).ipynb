{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow : Understanding Basics for NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Forward Propagation and Backwards Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we will use a Cost Function J(w) = w**2 - 10*w + 25, which is square of (w -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w here would be a variable, because we need to update w to optimize our cost for the given training set( **assumptions**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(0.0, dtype=tf.float32)\n",
    "cost = w**2 - 10*w + 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of defining our own gradient decent, tf.train.GradientDescentOptimizer(**alpha**).minize(cost) : it means for the given cost fucntion, with learning rate as alpha, compute gradient descent over the variable used in the cost function so that the value for cost is minimal(ideally zero)\n",
    "\n",
    "for example, \n",
    "when out cost function is cost = w**2 - 10*w + 25, we know that for w=5 our cost will be zero. this is what we'll compute using tensorflow's gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() #for initializing our variable w\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient decent for first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29404\n"
     ]
    }
   ],
   "source": [
    "sess.run(train)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.388159\n",
      "4.38838\n",
      "4.91889\n",
      "4.98924\n",
      "4.99857\n",
      "4.99981\n",
      "4.99997\n",
      "4.99999\n",
      "4.99999\n",
      "4.99999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train)\n",
    "    if(i%100==0):\n",
    "        print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
