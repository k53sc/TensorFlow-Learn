{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Basics\n",
    "\n",
    "Content From\n",
    "\n",
    "https://www.tensorflow.org/get_started/get_started\n",
    "\n",
    "## Veiwing this notebook correctly and making tensorflow snippets work\n",
    "\n",
    "The steps below would help executing the contents of this notebook\n",
    "- Create a new conda env. eg. \"tensorflow\"\n",
    "- Follow the steps from this link\n",
    "https://www.tensorflow.org/install/install_windows#installing_with_anaconda \n",
    "Perferably install the non-gpu version ( cuda doesn't like me )\n",
    "- Install Jupyter Notebook in the conda env \"tensorflow\"\n",
    "\n",
    "## Verify TensorFlow works in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is a tensor ?\n",
    "\n",
    "A Tensor can be thought of like a n-d matrix\n",
    "\n",
    "~~~\n",
    "  3   // Zero Dimensional Matrix- A scaler - a rank 0 tensor\n",
    " [3]  // One Dimensional Matrix- A Vector - a rank 1 tensor\n",
    "[[3]] // Two Dimensional Matrix- A Vector - a rank 2 tensor\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow objects\n",
    "\n",
    "TensorFlow operations are performed into a graph of nodes.  Each node takes zero or more tensors as inputs and produces a tensor as an output. Nodes can of following types\n",
    "- Constants\n",
    "- PlaceHolder\n",
    "- Variable\n",
    "\n",
    "## Constants\n",
    "\n",
    "One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=float32) Tensor(\"Const_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the nodes does not output the values 3.0 and 4.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippet below we assign the outcome of tf.add() to another node.\n",
    "\n",
    "We evaluate the new node by sess.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add_1:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "node3 = tf.add(node1, node2)\n",
    "print( \"node3:\", node3 ) # no evalution done at this step\n",
    "print(\"sess.run(node3):\", sess.run(node3)) # value of node 3 evaluated now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PlaceHolder\n",
    "\n",
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "# create two placeholder variables\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "\n",
    "# provie their value via dict and evalute the adder_node\n",
    "print(sess.run(adder_node, {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "\n",
    "PlaceHolders enable us to create a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# create two varaibles\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "\n",
    "# a placeholder\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model is a combination of varaible and placeholder\n",
    "linear_model = W*x + b\n",
    "\n",
    "# Constants are initialized when you call tf.constant, and their value can never change. \n",
    "# By contrast, variables are not initialized when you call tf.Variable.  \n",
    "# To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Since x is a placeholder, we can evaluate linear_model for several values of x simultaneously as follows\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function \n",
    "\n",
    "We've created a model, but we don't know how good it is yet. To evaluate the model on training data, we need a y placeholder to provide the desired values, and we need to write a loss function.\n",
    "\n",
    "A loss function measures how far apart the current model is from the provided data. We'll use a standard loss model for linear regression, which sums the squares of the deltas between the current model and the provided data. linear_model - y creates a vector where each element is the corresponding example's error delta. We call tf.square to square that error. Then, we sum all the squared errors to create a single scalar that abstracts the error of all examples using tf.reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "# Create a place holder variable\n",
    "# The input to this variable represents how our ideal model should be\n",
    "# In the above snippet we evaluated linear_model for several values of x simultaneously as follows\n",
    "# [ 0, 0.3, 0.6, 0.9 ]\n",
    "# The variable y computes the loss function wrt to the above linear model\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# standard\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing the Loss down to zero\n",
    "\n",
    "We could improve this manually by reassigning the values of W and b to the perfect values of -1 and 1. A variable is initialized to the value provided to tf.Variable but can be changed using operations like tf.assign. For example, W=-1 and b=1 are the optimal parameters for our model. We can change W and b accordingly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# although W and b were assigned some values initially\n",
    "# we can fix them by providing specific values\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "\n",
    "# fix the session to make sure fiwW and fixB get correct values\n",
    "sess.run([fixW, fixb])\n",
    "\n",
    "# compute the loss function again\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train API\n",
    "\n",
    "In the snippet above we guessed W and B to -1 and 1 to make the loss function return 0, can this be done automatically is the whole point of TensorFlow.\n",
    "\n",
    "TensorFlow provides optimizers that slowly change each variable ( W and b ) in order to minimize the loss function. The simplest optimizer is gradient descent. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. \n",
    "\n",
    "In nutshell tensorflow figures out for us the optimal values for W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [0.9999908] loss: 5.6999738e-11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
